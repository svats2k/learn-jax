{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnWJ4siglE8O"
   },
   "source": [
    "## W&B x JAX Meetup Series Notebook #1 \n",
    "\n",
    "This is notebook 1 from the JAX Study Group. To credit, this notebook was created by [Cristian Garcia](https://twitter.com/cgarciae88) with some additions made by [Sanyam Bhutani](http://twitter.com/bhutanisanyam1). \n",
    "\n",
    "To join the study group, please register for the Zoom webinar [here](http://wandb.me/JAX-registration) and join the JAX meetup page [here](https://www.meetup.com/jax-global-meetup/)\n",
    "\n",
    "Note: All meetups will be recorded and materials will be made available on the [forums](https://community.wandb.ai/c/community-events/jax/41)\n",
    "\n",
    "\n",
    "## Content Outline:\n",
    "\n",
    "- JAX vs Numpy\n",
    "- Automatic Differentiation\n",
    "- Vectorization\n",
    "- JIT Compilation\n",
    "- Parallelization\n",
    "- PyTrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqsM8alyakps"
   },
   "source": [
    "\n",
    "## Setup\n",
    "During this tutorial we are going to use Jax with a TPU to showcase some of its features, to do this go to `Runtime > Change runtime type` and select `TPU`. After that just run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvKxCGL9acn0",
    "outputId": "6fdda0d8-0436-48fa-c470-bade0d58ad0c"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'jax' has no attribute '_src' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23935/444062979.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Uncomment these lines for TPU:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#import jax.tools.colab_tpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#jax.tools.colab_tpu.setup_tpu()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/repos/personal/learn-jax/venv/lib/python3.8/site-packages/jax/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mnumpy_rank_promotion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnumpy_rank_promotion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m )\n\u001b[0;32m---> 53\u001b[0;31m from ._src.api import (\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0mad\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# TODO(phawkins): update users to avoid this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0mcheckpoint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/repos/personal/learn-jax/venv/lib/python3.8/site-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m flags.DEFINE_bool(\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m\"experimental_cpp_pmap\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mbool_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JAX_CPP_PMAP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xla_extension_version\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m39\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;34m\"A flag enabling the C++ jax.pmap fast path. Until the default \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;34m\"is switched to True, the feature is not supported and possibly broken \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'jax' has no attribute '_src' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "#Uncomment these lines for TPU:\n",
    "#import jax.tools.colab_tpu\n",
    "#jax.tools.colab_tpu.setup_tpu()\n",
    "#jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPBZUlApSiy9"
   },
   "source": [
    "For TPU,\n",
    "If all went well you should see `8` devices.\n",
    "\n",
    "Note:\n",
    "You should see a GPU ID if you're trying this w GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2_G-ByRTgnE"
   },
   "source": [
    "## Numpy API\n",
    "[`Numpy`]() is the bread and butter of all MLEs toolbox. \n",
    "\n",
    "Jax's primary \"tensor\" abtraction and API is good old Numpy array and the Numpy API which is available as `jax.numpy`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UV6wCqammqJ_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Jax offers a `jax.numpy` API\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZ4ccRzhm2Lg"
   },
   "source": [
    "Let's take a peek at the function differences, as we'll see from the output, almost the entirity of the functions supported by `numpy` are present in `jax.numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CS0uCGJlmzPH",
    "outputId": "2048ed69-347d-46a9-9b29-1f80464fd64c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 474\n"
     ]
    }
   ],
   "source": [
    "np_funcs = set(dir(np))\n",
    "jnp_funcs = set(dir(jnp))\n",
    "\n",
    "print(len(np_funcs)  , len(jnp_funcs.intersection(np_funcs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvDAtp59oIxV",
    "outputId": "4417e5dd-df18-4812-84ff-07880086c449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timedelta64', 'busdaycalendar', 'AxisError', '__git_revision__', 'ERR_WARN', 'SHIFT_DIVIDEBYZERO', 'long', 'Tester', 'WRAP', '_distributor_init', 'void0', 'ushort', 'random', 'FPE_DIVIDEBYZERO', 'nbytes', 'core', 'nditer', 'tracemalloc_domain', 'ERR_LOG', 'uintc', '_mat', 'str', 'ma', 'sctypeNA', 'complex', '__dir__', 'ERR_DEFAULT', 'string_', 'True_', 'MAY_SHARE_BOUNDS', 'MAXDIMS', 'FPE_UNDERFLOW', 'generic', 'clongfloat', 'Infinity', 'ScalarType', 'half', 'memmap', 'emath', 'warnings', 'FPE_OVERFLOW', 'TooHardError', 'ERR_IGNORE', 'UFUNC_BUFSIZE_DEFAULT', 'record', 'longlong', 'matrixlib', 'bytes0', 'flatiter', '_UFUNC_API', 'errstate', 'clongdouble', 'unicode', 'unicode_', 'short', 'ERR_PRINT', 'intc', 'longfloat', 'numarray', 'DataSource', 'VisibleDeprecationWarning', 'PINF', 'kernel_version', '__all__', 'test', 'False_', 'ERR_RAISE', 'format_parser', 'UFUNC_PYVALS_NAME', 'Inf', '__getattr__', 'ulonglong', 'float128', 'sctypeDict', 'cast', 'NAN', 'SHIFT_INVALID', 'recarray', 'BUFSIZE', 'testing', 'compat', 'ndenumerate', 'bool8', 'int0', 'rec', 'object0', 'math', 'str_', 'typecodes', 'char', 'FPE_INVALID', 'NaN', 'little_endian', 'typeDict', 'ERR_CALL', 'MAY_SHARE_EXACT', 'broadcast', 'sys', 'longcomplex', 'bool', 'MachAr', 'void', 'SHIFT_UNDERFLOW', 'sctypes', 'SHIFT_OVERFLOW', 'float', 'use_hugepage', 'RAISE', 'RankWarning', 'object', 'poly1d', 'CLIP', '__config__', 'str0', '_pytesttester', 'byte', 'typeNA', 'dual', 'bytes_', 'uintp', 'int', '_globals', '__version__', 'ubyte', 'FLOATING_POINT_SUPPORT', 'uint', 'matrix', 'singlecomplex', 'chararray', 'intp', 'datetime64', '_NoValue', 'version', 'ALLOW_THREADS', 'lib', 'infty', 'ufunc', 'ModuleDeprecationWarning', 'ndindex', 'oldnumeric', 'os', 'polynomial', 'ctypeslib', 'cfloat', '__NUMPY_SETUP__', 'longdouble', 'uint0', 'complex256'}\n"
     ]
    }
   ],
   "source": [
    "print(np_funcs.difference(jnp_funcs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmKc_ewVmqle"
   },
   "source": [
    "This is one of its best features because its familiar to almost everyone on the field, take a look at the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmgaLEai7AXq"
   },
   "outputs": [],
   "source": [
    "?jnp.meshgrid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KnLgSzTPSNZf",
    "outputId": "69afbf24-674e-4b82-8c01-dd6fbd2607c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (100, 100)\n",
      "Y: (100, 100)\n"
     ]
    }
   ],
   "source": [
    "x = jnp.linspace(0, 1, 100)\n",
    "y = jnp.linspace(0, 10, 100)\n",
    "\n",
    "X, Y = jnp.meshgrid(x, y)\n",
    "\n",
    "print(\"X:\", X.shape)\n",
    "print(\"Y:\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_71KQIwptYg"
   },
   "source": [
    "## Reminder: JAX ~= Numpy on Accelerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luwYv4cUps8H"
   },
   "outputs": [],
   "source": [
    "#Source: JAX ReadMe\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "\n",
    "def predict(params, inputs):\n",
    "  for W, b in params:\n",
    "    outputs = jnp.dot(inputs, W) + b\n",
    "    inputs = jnp.tanh(outputs)  # inputs to the next layer\n",
    "  return outputs                # no activation on last layer\n",
    "\n",
    "def loss(params, inputs, targets):\n",
    "  preds = predict(params, inputs)\n",
    "  return jnp.sum((preds - targets)**2)\n",
    "\n",
    "grad_loss = jit(grad(loss))  # compiled gradient evaluation function\n",
    "perex_grads = jit(vmap(grad_loss, in_axes=(None, 0, 0)))  # fast per-example grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9PZUJXN9NRB"
   },
   "source": [
    "## Differences:\n",
    "\n",
    "Credit: [JAX Sharp Bits Colab by JAX Team](https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/Common_Gotchas_in_JAX.ipynb#scrollTo=om4xV7_84N9j)\n",
    "- In place modify doesn't work\n",
    "- `jnp.random` doesn't exist! You have to use `jax.random` which offers the same functions **BUT** it is you have to explicitly handle the random state (RNG) that is compatible with Jax's functional programming model.\n",
    "- Updated Array is a new Array\n",
    "- Out of place updates\n",
    "- Non Array Inputs\n",
    "- Using `double`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcc8izot9Lr4",
    "outputId": "7f331417-4931-49a7-c5dc-3c59fb51002d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original array:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "updated array:\n",
      "[[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = np.zeros((3,3), dtype=np.float32)\n",
    "print(\"original array:\")\n",
    "print(numpy_array)\n",
    "\n",
    "# In place, mutating update\n",
    "numpy_array[1, :] = 1.0\n",
    "print(\"updated array:\")\n",
    "print(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l00XGeb6pr_Y",
    "outputId": "1428e217-3245-41d7-b9b6-78d30d6744fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception '<class 'jax.interpreters.xla._DeviceArray'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/jax.ops.html\n"
     ]
    }
   ],
   "source": [
    "jax_array = jnp.zeros((3,3), dtype=jnp.float32)\n",
    "\n",
    "# JAX Arrays are immutable\n",
    "try:\n",
    "  jax_array[1, :] = 1.0\n",
    "except Exception as e:\n",
    "  print(\"Exception {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgDUfrz1AKSh",
    "outputId": "5b476fbb-6f73-458e-8ba8-ec3c2cba1201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated array:\n",
      " [[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "original array unchanged:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "updated_array = jax_array.at[1, :].set(1.0)\n",
    "print(\"updated array:\\n\", updated_array)\n",
    "\n",
    "print(\"original array unchanged:\\n\", jax_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWXbQNCN74-1",
    "outputId": "3250b811-542a-4cc8-ba22-2e8e239b3d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20584236]\n"
     ]
    }
   ],
   "source": [
    "from jax import random\n",
    "key = random.PRNGKey(0)\n",
    "key\n",
    "\n",
    "print(random.normal(key, shape=(1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "3iHJU1eSAQf4",
    "outputId": "bfda73be-1151-4cce-929c-b46005ce2845"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-0479a5407519>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    #No error\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "print((jnp.arange(10)[100])\n",
    "#No error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZ6znWI5AUUE",
    "outputId": "42d57739-8501-47dc-bbd2-3e069e1609d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: sum requires ndarray or scalar arguments, got <class 'list'> at position 0.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  jnp.sum([1, 2, 3])\n",
    "except TypeError as e:\n",
    "  print(f\"TypeError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GkJ04jRvAjUZ",
    "outputId": "013e9b35-9a8c-486e-a744-216cbf844e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random.uniform(random.PRNGKey(0), (1000,), dtype=jnp.float64)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7YH5LAgBAn1"
   },
   "outputs": [],
   "source": [
    "#Do this to enable higher precision:\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGg1CiEgTm6J"
   },
   "source": [
    "Apart from the `numpy` API has a suite of function transformations which let you easily perform computations that can be hard on other frameworks. We will these transformations next!\n",
    "\n",
    "## Automatic Differentiation\n",
    "One of the most important aspects of a modern Linear Algebra library is Automatic Differentiation. To explore how Jax achieves this lets first view a simple example of the density function of the normal distribution which has the form:\n",
    "\n",
    "$$ \n",
    "f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right) \n",
    "$$\n",
    "\n",
    "This is available in Jax as `jax.scipy.stats.norm.pdf` and behaves just like its Scipy counterpart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "f_mmwC5hTXgt",
    "outputId": "e75131e5-e3c4-4a06-bbf4-ebdd251c703d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = jnp.linspace(-4, 4, 100)\n",
    "y = jax.scipy.stats.norm.pdf(x)\n",
    "\n",
    "plt.plot(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnZqTLfAaG16"
   },
   "source": [
    "Here we used the default parameters \\\\( {\\mu} = 0 \\\\) and \\\\( {\\sigma} = 1 \\\\). Now if we wanted its derivative we could probably get an exact expressionby hand but in Jax we can leverage the `grad` function which will transform our function into a function that returns its gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRmCHy4rUcpx",
    "outputId": "91ae7ac0-3c11-44bd-b653-4a0bb8605224"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-5.0: DeviceArray(7.433706e-06, dtype=float32),\n",
       " -1.0: DeviceArray(0.24197444, dtype=float32),\n",
       " 0.0: DeviceArray(-0., dtype=float32),\n",
       " 1.0: DeviceArray(-0.24197444, dtype=float32),\n",
       " 5.0: DeviceArray(-7.433706e-06, dtype=float32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_fn = jax.grad(jax.scipy.stats.norm.pdf)\n",
    "\n",
    "{\n",
    "  -5.0: grad_fn(-5.0), \n",
    "  -1.0: grad_fn(-1.0),\n",
    "   0.0: grad_fn(0.0), \n",
    "   1.0: grad_fn(1.0), \n",
    "   5.0: grad_fn(5.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrTyoYREdojT"
   },
   "source": [
    "Here we evaluated the derivative of the density function at five points which match our intuition about the functions behavious: almost `0` at `-5`, positive at `-1`, flat at `0`, netative at `-1`, and then almost `0` at `-5`. As its common in Numpy, We could be tempted to calculate this for the whole domain but we will get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BgTb5TzYDQx",
    "outputId": "e84cae15-149e-49cd-c484-7f1bd6812d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient only defined for scalar-output functions. Output had shape: (100,).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  dydx = grad_fn(x)\n",
    "except BaseException as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTo_cjUVedqA"
   },
   "source": [
    "As the message points out, the gradient of a function is only defined for a scalar output and here we are returning a vector. To solve this we can explore vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoxzuWhaXDxu"
   },
   "source": [
    "## Vectorization\n",
    "Jax provides a function called `vmap` which lets us transform a function that works with arrays without an explicit batch dimension into a function that now accepts arrays with a batch dimension. Very loosely we are performing the following transformation:\n",
    "```\n",
    "(a...) -> (b...) => (batch, a...) -> (batch, b...)\n",
    "```\n",
    "Notice how `batch` pops-up in the shapes of the resulting function. For our use-case, since our `grad_fn` only operates on scalars, we can _simply_ use `vmap` to make it work on vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "LUeoxpF1V1CC",
    "outputId": "0fe7fc89-72fc-438b-d3bc-4b3b5ff0cbe9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8dcn+0r2hEAICSQsYZcAgoAVouJKF3fr0s1OW7eOtWptsXXsb6xLa2faaUWd0VqXWsWCiKBQK1rZwr6EBAgQkhCy78vNvff7+yPBiUwQyL255y6f5+ORB3c53vMWyJuT7znn+xVjDEoppfxfkNUBlFJKeYYWvlJKBQgtfKWUChBa+EopFSC08JVSKkCEWB3gdJKTk01WVpbVMZRSyqds3bq11hiT0t97Xlv4WVlZFBYWWh1DKaV8iogcPd17OqSjlFIBQgtfKaUChBa+UkoFCC18pZQKEFr4SikVILTwlVIqQGjhK6VUgPDa6/BV4Gru7GZzaT0l1S1kJESRkxLDqJRoIkKDrY6mlE/TwldewRjDqt1VLF1/iN0VTThPWaYhLDiIb87N5u6FOUSF6V9bpQZCv3OU5cob2lmyfC9/31/N2LRY7lyQy+xRSUwYPoTKxg4OnGjlw/3V/PGjQ6zYUcGSq/K4dMJQRMTq6Er5FPHWFa/y8/ONTq3g/1bsrOTBt3YB8K8Xj+H2OVmEBPd/amnLkXp+9rc97K9q4d6CXO4tGOPJqEr5BBHZaozJ7+89PcJXlvnLljIeXLabGSMT+fX1U8hIiPrC7WdkJbLyrrk8uGw3z6w9wJCIUL45N9tDaZXyfVr4yhIvfXqER1bs5cIxKTx7y/SzPiEbEhzE41+dRGunnUdX7iMuMpSvTc8Y5LRK+Qe9LFN53Msbesr+4rw0lt569mV/UkhwEL+9cSpzc5L58Vu7+ORA7eAEVcrPaOErj/r0UC0/f2cfBeNT+a+bzyM8ZGCXWoaHBPPsLdPJTo7mgbd20dZld3NSpfyPFr7ymPKGdu58dTvZydH85vqphJ7m5OzZig4P4Vdfm0RlUwdPril2U0ql/JcWvvKIDpuD7768lW6Hk6W3TCc2ItQtnzt9ZCK3nj+SlzYcYevRBrd8plL+SgtfecQjK/aw73gzv71hKqNSYtz62fcvGkf6kAgeeGsXXXaHWz9bKX+iha8G3bqiE7xRWM73LhzNgnFpbv/8mPAQfvnVSRysbuWFTw67/fOV8hda+GpQNbTZeHDZbsYNjeWegtxB289FY1P50tgUnltfqidwlToNLXw1qB5ZsZeGNhtPXzdlwFfknK27F+bS0N7NyxtPu4azUgFNC18NmlW7j7NiZyX3LMxlwrC4Qd/feZkJzMtN5rn1pbTb9ChfqVO5pfBFZJGIFIvIQRF5sJ/3/1VE9onILhFZJyIj3bFf5b2aO7t5ZMVeJg2P43tfGu2x/d5bkEtdm41XNpZ5bJ9K+QqXC19EgoHfA5cBecCNIpJ3ymbbgXxjzGTgTeAJV/ervNtvPiihtrWLX35l4mknQxsM00cmMjcnmWfXH6LDplfsKNWXO74TZwIHjTGlxhgb8DqwuO8GxpgPjTHtvU83Ajr5iR/bV9nMS58e4eZZmUzOiPf4/u9emEttq43XNutRvlJ9uaPwhwPH+jwv733tdL4FvNffGyJyh4gUikhhTU2NG6IpT3M6DUuW7yE+KowfXTLWkgwzsxM5LzOeP288irdO/62UFTx60lZEvg7kA0/2974xZqkxJt8Yk5+SkuLJaMpNlm2voPBoAw8uGkd8VJhlOW6eNZLS2jY2lNZZlkEpb+OOwq8ARvR5ntH72ueISAHwMHC1MabLDftVXqa1y87j7+1nWmY811g8ZfEVk9OJiwzl1U06rKPUSe4o/C1Arohki0gYcAOwou8GIjINeJaesq92wz6VF/rjPw5R29rFI1dNICjI2uUHI0KD+ep5w1mzt4raVj2+UArcUPjGGDtwJ7AGKALeMMbsFZFHReTq3s2eBGKAv4rIDhFZcZqPUz6qsrGD5z4u5eopw5g6wvMnavtz86xMuh2GN7eWWx1FKa/glhWvjDGrgFWnvLakz+MCd+xHea+n1hRjgB8vsuZEbX9yUmOZmZXIq5vKuGPeKMt/6lDKanqnrXLZrvJGlm2v4JsXZJ9xXVpPu/n8TMrq2/nnIV0VSyktfOUSYwy/fLeIxOgwvn+R5+6oPVuLJg4lISqUv2w5duaNlfJzWvjKJf8ormHT4XruWZjLEDctauJO4SHBXD4pnXVF1Tq/jgp4WvhqwJxOw69W7yczMYobZ2ZaHee0rpoyjI5uB2uL9AIxFdi08NWArdhZyf6qFu67ZAxhId77V2lGViJpQ8J5Z2el1VGUspT3fpcqr2azO3n6g2ImDBvCVZOHWR3nCwUHCVdMGsZHxTU0dXRbHUcpy2jhqwF5ddNRjtV38ONF43zicserpqRjczh5f2+V1VGUsowWvjpnbV12fvfhQWaPSmJ+brLVcc7K1BHxZCREsnLXcaujKGUZLXx1zv77k8PUttr48aKxiHj/0T2AiHDVlGF8crCW+jab1XGUsoQWvjonje02lq4v5eK8NKZlJlgd55xcNXkYDqfhvT16lK8Ckxa+Oid//KiUVpvdsrnuXTE+PZZRKdG8q8M6KkBp4auzVt3cyYufHubLU4czdmis1XHOmYhwSd5QNh+u16t1VEDSwldn7T//fhC7w3BvQa7VUQasYHwqdqfhoxJdUU0FHi18dVbK6tp5fUsZ188YwcikaKvjDNi0zAQSo8NYV3TC6ihKeZwWvjorz6wtIUiEuxf67tE99NyEtWBcKh/ur6bb4bQ6jlIepYWvzqjkRAtv76jg9jlZpA2JsDqOywrGp9LcaafwSIPVUZTyKC18dUZPv19MTFgI/3Kh901/PBDzclMICw7SYR0VcLTw1RfacayRNXtP8J35o0iIDrM6jltEh4cwe3QSa4tOYIyxOo5SHqOFr77QU2uKSYoO45tzs62O4lYFeWkcqWvnUE2b1VGU8hgtfHVa/zxYyycHa/n+RTnEhLtl+WOvsXBcKgBrdVhHBRAtfNUvY3oWNxkeH8nNs7x3cZOBGhYfSV76EB3HVwFFC1/1a9XuKnaVN/HDi8cQERpsdZxB8aWxKWwra6SlU++6VYFBC1/9H90OJ0+9X8zYtFi+Mm241XEGzfwxKTichk8P1VkdRSmP0MJX/8cbhcc4XNvG/ZeOJdgHFjcZqPMyE4gKC+bjAzrNggoMWvjqc9ptdn679gD5IxNYOD7V6jiDKiwkiNmjkvj4QK3VUZTyCC189TnPf3yY6pYuHrxsnM8sbuKK+WNSOFrXztE6vTxT+T8tfPWZ6pZO/vjRIS6bOJT8rESr43jEvN4lGtfrUb4KAFr46jO/+eAANruTBxaNszqKx2QnR5OREMl6nS5ZBQAtfAX0TJD2ly1l3DJ7JFnJvjv98bkSEeblprDhUJ3Onqn8nha+AuDfVxURHR7C3Qt8e/rjgZifm0xrl53tZY1WR1FqUGnhK9aX1PBhcQ13XpTjNxOknYs5OckECXp5pvJ7WvgBrtvh5NGV+xiZFMXtF2RZHccScZGhTB0Rr+P4yu+5pfBFZJGIFIvIQRF5sJ/354vINhGxi8g17tinco8/bTjKwepWfnZFHuEh/jmFwtmYm5PM7oommnWaBeXHXC58EQkGfg9cBuQBN4pI3imblQG3A6+6uj/lPrWtXTyztoT5Y1L8/iarMzl/dBJOA5tL662OotSgcccR/kzgoDGm1BhjA14HFvfdwBhzxBizC9DLILzIU2uK6bA5WHJlXkDcZPVFzstMICwkiA2lOq+O8l/uKPzhwLE+z8t7XztnInKHiBSKSGFNjY6nDqbd5U38pfAYt8/JIic1xuo4losIDWZ6ZoJOpKb8mledtDXGLDXG5Btj8lNSUqyO47ccTsNP3t5Nckw4dxcE3mWYpzNndBJFx5tpaLNZHUWpQeGOwq8ARvR5ntH7mvJSf9pwhN0VTSy5Mo8hEaFWx/Eas0cnAbDpsB7lK//kjsLfAuSKSLaIhAE3ACvc8LlqEFQ1dfL0+yVcOCaFKyenWx3Hq0zOiCcqLFiHdZTfcrnwjTF24E5gDVAEvGGM2Ssij4rI1QAiMkNEyoFrgWdFZK+r+1UD84t39tLtcPJviycG/InaU4WFBJGflcgGLXzlp9yyMrUxZhWw6pTXlvR5vIWeoR5lobX7TvDeniruv3QsmUlRVsfxSnNGJ/H4e/upbukkNTbC6jhKuZVXnbRVg6ex3cZDb+9m3NBYvjNvlNVxvNbsUT3j+Bv1enzlh7TwA8TPV+yloc3G09dNISxE/9hPZ8KwIcRGhOiwjvJL+p0fAFbvqeJvOyq5c0EOE4bFWR3Hq4UEBzErO5ENh3RBFOV/tPD9XH2bjZ/+bTd56UP4wUU5VsfxCeePSuJIXTsnmjutjqKUW2nh+zFjDA+8tYumjm6evm4KocH6x302Zmb3LO+4+bCO4yv/og3gx17eeJQP9p3ggUXjGJ8+xOo4PiMvfQgx4SF6A5byO1r4fmpvZROPrSziorEpfGtuttVxfEpIcBDTRyboEb7yO1r4fqjdZueu17YTHxXKU9dO0RusBmBmdiIlJ1qp13l1lB/RwvczxhgeWrabw7VtPHPDVJJiwq2O5JNm9Y7jbzmiR/nKf2jh+5nnPi5l+Y5K7rt4DHNGJ1sdx2dNyogjPCSITXoDlvIjWvh+5KOSGh5/bz9XTErXSzBdFB4SzHmZCWw+oidulf/QwvcTR2rbuOvVbYxJi+XJayfruL0bzMxOZF9ls65zq/yGFr4fqG3t4vb/2UxwkPDcrflEhbllTryANys7EaeBrUcbrI6ilFto4fu41i4733xxC1XNnTx/2wxGJOosmO4yLTOBkCDRcXzlN/RQ0IfZ7E6+9+et7K1s5rlbpzN9ZILVkfxKZFgwkzPi2Kw3YCk/oUf4Pqrb4eSHf9nBxwdqefyrk1gwLs3qSH5pZnYSu8qb6LA5rI6ilMu08H2Qze7krle38+7u4/z0ivFcmz/izP+RGpCZ2QnYnYYdxxqtjqKUy7TwfUyX3cH3X9nG6r1VLLkyj2/rYiaDanpmIiJ6A5byDzqG70NaOrv5wavbWV9Sw78tnsAts7OsjuT34qJCGZsWq4Wv/IIe4fuIysYOrv3jBv55sJYnvjZZy96D8rMS2Ha0AbvDaXUUpVyihe8D9lQ08ZX/+icVDR28+I0ZXDdDx+w9aUZWIm02B/urWqyOopRLtPC9mDGG1zaX8bU/fEpIUBBvfm8O83JTrI4VcGZk6URqyj9o4Xup1i4797y+g4eW7WZmdiLL77yAsUNjrY4VkIbFRzI8PlILX/k8PWnrhT49VMtDy3ZzrL6d+y8dy/cuHE1QkM6NY6UZWQn881Adxhidp0j5LD3C9yJNHd08+NYubnpuEwCvfed8fnBRjpa9F8jPSqSmpYujde1WR1FqwPQI3wvYHU7eKCzn1x+UUN/WxXfnj+LegjFEhgVbHU31mtlnQZSs5GiL0yg1MFr4FjLGsK6omsdX7+dgdSv5IxP4n9tnMCkjzupo6hQ5KTHERYZSeKRB72xWPksL3wLdDicrd1Xy7Eel7K9qYVRyNM/eMp1L8tJ0fNhLBQUJ+SMT9MSt8mla+B5U2djBXwvL+cuWMiqbOhmTFsPT107h6qnDCA3W0ynebkZ2Iuv2V1Pb2kWyrhWsfJAW/iBrbLfxwb4TrNx1nPUHajAGLshJ4tHFE1kwLlVPyPqQGVk9008XHmlg0cShFqdR6txp4buZ02koPtHCJwdq+aikhg2ldTichuHxkdx5UQ7XTh9BZpIuUuKLJg6PIywkiK1H67XwlU/SwndRc2c3+yqb2V7WyPayBraVNVDbagNgdEo035k3issmDmVyRpyOz/u48JBgpmbEs+WILnmofJNbCl9EFgG/BYKB540xj5/yfjjwJ2A6UAdcb4w54o59e0Jnt4Oqpk4qGjs4XNvG0bo2DtW0UVzVQkVjx2fbZSVFMT83hdmjk5ibm0x6XKSFqdVgmJ6VwHPrS+mwOfSyWeVzXC58EQkGfg9cDJQDW0RkhTFmX5/NvgU0GGNyROQG4FfA9a7u+2wZY7A5nHTZnXTYHHTYHLTbHLTZ7LR22mnpstPc0U1TRzeN7Tbq2mzUttqobemiuqXzsyP2k8JDgshKimb6yARumpVJXvoQpoyIJzE6zFP/S8oiM7IS+MM/ehZEmT06yeo4Sp0TdxzhzwQOGmNKAUTkdWAx0LfwFwM/7338JvA7ERFjjHHD/j+nrrWLK//zE2x2JzaHk+7eoj/bPUWFBZMQFUZyTBjpcRFMGRFHelwk6XERDE+IJCspmqFDIvRka4CantlzA1bhkXotfHXWuh3OnoPLTjttNjsd3T0Hnp3dDjq7nXTZHdjs/9tXyTHhfHnacLfncEfhDweO9XleDsw63TbGGLuINAFJQG3fjUTkDuAOgMzMzAGFiQgNZl5uMqHBQYQGBxEWEkR4SBARocGf/RoVFkxkaDAxESHEhIcQGxFCbEQocZGhRITqj+nq9E4uiFJ4VMfxA123w0llYwcVjR0cb+ykqrmTmpYualq7qGvtorG9u+erw0Zn97mtpTBlRLzXFr7bGGOWAksB8vPzB3T0Hx0ewhPXTHFrLqX6ys9KYMWOShxOQ7D+pOf3uh1OSk60sP94C8UnWiiuauFoXRvlDR3YnZ+vqdiIEFJiwkmOCWdkUhSTM3oOJOMiQ4kJDyG69yuy96AzMjT4s4PR8NCgzw5Uw0MG574cdxR+BdD3XvOM3tf626ZcREKAOHpO3irlc/KzEnhlUxnFVS3kDRtidRzlZi2d3WwqrWfT4Tq2lzWyu6KJLnvPEXpYSBCjU2KYMDyOKycPIzMpioz4SNLjIxk6JMLrT+S7o/C3ALkikk1Psd8A3HTKNiuA24ANwDXA3wdj/F4pT8gf2TuOf7ReC99PlNa0snpvFX8vqmbHsUbsTkNYSBAThw3h6+ePZMqIePLSY8lKiibEh++Kd7nwe8fk7wTW0HNZ5n8bY/aKyKNAoTFmBfAC8LKIHATq6flHQSmflJHQczS35UgDt+rawj7rRHMnb24tZ8WOSopP9CxfOTkjju9eOIoLcpI5LzPB787puWUM3xizClh1ymtL+jzuBK51x76UspqIkJ+VwFadSM3nGGP4qKSGP28s48PiahxOw4ysBJZcmceiiUMZFu/f98541UlbpXzFjKxEVu46TnlDOxkJOlWGt7M7nLy7+zh/+Mch9le1kBwTzh3zR3Fd/giyA2h9Ay18pQYgv89Ealr43ssYw+o9VTyxppjDtW3kpMbw5DWTWTx1OGGDdCWMN9PCV2oAxg0dQkx4CFuO1A/K9dLKddvKGnhs5T62lTUyJi2GpbdMp2B8WkDfNKmFr9QABAcJ5+mCKF6ptcvOE6v38/LGo6TEhPP4VydxzfQMn766xl208JUaoJlZCTz1fg2N7Tbio3QeJW/wYXE1Dy/bzfHmTm6bncX9l44lOlxr7iT9nVBqgPKzeq7H33q0gYXj0yxOE9hsdidPrN7P858cJjc1hjf/ZQ7TRyZYHcvraOErNUBTR8QTGixsPlKvhW+hY/Xt3PnadnYea+TW2SP5yeXj/e76eXfRwldqgCJCg5k0PI5CXRDFMptK6/jun7ficBj+6+bzuHxSutWRvJqexVDKBTOyEtlV3khnt8PqKAFn2bZyvv7CJpKiw3jnrrla9mdBC18pF8zISqTbYdh5rNHqKAHDGMMza0v41zd2kj8ykWXfu4CsALp5yhVa+Eq54OSJQb080zOMMTz2bhHPrD3A187L4KVvziQuKtTqWD5Dx/CVckFCdBhj0mJ0YXMPMMbwi3f28eKnR7h9ThaPXJWHSODeRDUQeoSvlIvysxLZdrQBh1Nn/B4sxhh+tnwPL356hG/PzdayHyAtfKVcNCMrgZYuO0XHm62O4rd+tbqYP28s47sXjuLhK8Zr2Q+QFr5SLpqZ3bOYuY7jD47nPy7ljx8d4uvnZ/LgonFa9i7QwlfKRcPjIxkeH8nmw1r47va37RU89m4Rl00cyi+unqhl7yItfKXcYNaoRDYfrkdX7nSfjaV1/OivO5mVnchvrp+qC8a7gRa+Um4wKzuRujYbh2parY7iF8ob2vn+K9vITIpi6a35OlWCm2jhK+UGJ8fxN+mwjss6bA7u+NNWuu1Onrs1n7hIvc7eXbTwlXKDrKQoUmLDdRzfRcYY7n9zJ0VVzfzHjdMYnRJjdSS/ooWvlBuICLOyE9lUquP4rnjx0yOs3HWc+y8dy0XjUq2O43e08JVyk1nZiVQ1d3KsvsPqKD5pT0UT/75qPwXjU/nehaOtjuOXtPCVcpP/HcevsziJ72ntsnPXa9tJjA7jiWum6OWXg0QLXyk3yU2NIT4qVMfxB2DJ8j0crWvjmRumkhity0UOFi18pdwkKEiYmZWoV+qco+U7Kli2rYK7FuRy/qgkq+P4NS18pdxoZnYiZfXtHG/ScfyzUd3cyZLle5mWGc9dC3KsjuP3tPCVcqNZJ8fxS/Uo/0yMMfzk7d10djt46tophARrHQ02/R1Wyo3yhg1hSEQIGw7pidszeXt7BWuLqrn/0rF6vb2HaOEr5UbBQcKsUUlsKNXC/yInmjv5+Yq9zMhK4BsXZFsdJ2Bo4SvlZrNHJVFW3055Q7vVUbzWI8v3YnM4efKaKTopmgdp4SvlZnNyesbxdVinf+uKTrB6bxV3L8zVxcc9TAtfKTcbkxpLYnSYDuv0o91mZ8nyvYxJi+E780ZZHSfguFT4IpIoIh+IyIHeXxNOs91qEWkUkZWu7E8pXxAUJMwelcSGQ3U6r84pnll7gIrGDv7fVyYRqlfleJyrv+MPAuuMMbnAut7n/XkSuMXFfSnlM84fncTxpk6O1uk4/klFx5t54ZPD3DBjBPlZiVbHCUiuFv5i4KXexy8BX+5vI2PMOqDFxX0p5TPmjO4Zx/9Ux/GBnmvulyzfQ1xkKA9eNs7qOAHL1cJPM8Yc731cBaS58mEicoeIFIpIYU1NjYvRlLLOqORoUmPDdRy/1zu7jrPlSAP3XzqW+CidK8cqIWfaQETWAkP7eevhvk+MMUZEXBqwNMYsBZYC5Ofn6+Cn8lkiwuzRSfzzYM84fiDP/thus/P/3i1iwrAhXJc/wuo4Ae2MhW+MKTjdeyJyQkTSjTHHRSQdqHZrOqV82JzRSSzfUcnB6lZy02KtjmOZP/zjEFXNnfzupml6zb3FXB3SWQHc1vv4NmC5i5+nlN+YMzoZgH8erLU4iXXK6tp5dn0pi6cO0xO1XsDVwn8cuFhEDgAFvc8RkXwRef7kRiLyMfBXYKGIlIvIpS7uVymvNyIxiqykKD4+ELiF//jqIoJF9EStlzjjkM4XMcbUAQv7eb0Q+Haf5/Nc2Y9SvmpebgpvbSvHZncSFhJY151vPVrPqt1V/LBgDOlxkVbHUeidtkoNqnm5ybTbHGw92mB1FI8yxvDYu0Wkxobznfk6OZq30MJXahDNHp1ESJDw8YHAusx41e4qtpc18qNLxhIV5tJAgnIjLXylBlFsRCjnZSawPoAKv8vu4Fer9zNuaCxfm55hdRzVhxa+UoNsXm4yeyqaqWvtsjqKR7y84Shl9e08dPl4vQzTy2jhKzXI5o9JAeCTALg8s7mzm999eJB5uclc2Pv/rbyHFr5Sg2zi8Djio0JZX+L/hf/sR4dobO/mgUV6GaY30sJXapAFBwkX5CTz8YEav54uubq5kxc+OcxVU4YxcXic1XFUP7TwlfKAC3NTqG7pouREq9VRBs1v1x3A7jDcd/EYq6Oo09DCV8oD5o3pmWbhH8X+Od3U4do2Xt9yjBtnZuqyhV5MC18pD0iPi2R8+hDW7ffPwn/q/WLCgoO4a2GO1VHUF9DCV8pDCsanUniknoY2m9VR3GpPRRPv7jrOt+ZmkxobYXUc9QW08JXykILxaTgN/KPEv47yn36/mLjIUL4zXxcl93Za+Ep5yKThcaTGhrN2n/8U/pYj9XxYXMO/XDiauMhQq+OoM9DCV8pDgoKEheNT+aikBpvdaXUclxljeGL1flJiw7l9TpbVcdRZ0MJXyoMKxqfR2mVn02HfX+v2o5Iathxp4O4FOUSGBVsdR50FLXylPOiCnGQiQoNYu++E1VFc4nQanlxTzIjESK6fkWl1HHWWtPCV8qCI0GDm5qSwtqjap++6fW9PFXsrm/lhwZiAW9jFl+mflFIeVjA+lYrGDvZXtVgdZUDsDidPf1DMmLQYFk8dbnUcdQ608JXysAXjUwH4wEeHdZZtq6C0po37Lhmr0x/7GC18pTwsNTaCGVkJvLvruNVRzlmX3cEza0uYkhHHJXlpVsdR50gLXykLXDVlGMUnWij2sWGdVzeVUdnUyf2XjkNEj+59jRa+Uha4bGI6QQIrd1VaHeWstXbZ+f2HB5k9KokLcpKsjqMGQAtfKQukxIYzZ3Qy7+ys9JmrdZ7/uJTaVhs/XjRWj+59lBa+Uha5ako6R+ra2VPRbHWUM6pt7eK59aUsmjCUaZkJVsdRA6SFr5RFLp0wlNBg4R0fGNb53d8P0tHt4EeXjrU6inKBFr5SFomPCmNebgord1bidHrvsM6x+nZe2XSU62eMICc1xuo4ygVa+EpZ6Kop6VQ2dbKtrMHqKKf16w9KCBLhnoW6dKGv08JXykIX5w0lPCSIv+2osDpKv/ZUNPH29gq+cUE2Q+N0cRNfp4WvlIViwkO4fFI6y7dX0m6zWx3nc4wxPPbuPhKjw/j+RaOtjqPcQAtfKYvdNCuTli477+z0rpO3a4uq2Vhaz70FuQyJ0MVN/IEWvlIWyx+ZQG5qDK9uKrM6yme6HU7+fVURo1KiuXGmTn/sL7TwlbKYiHDTrEx2ljexp6LJ6jhAzxQKpbVtPHz5eEKDtSb8hUt/kiKSKCIfiMiB3l//zx0ZIjJVRDaIyF4R2SUi17uyT6X80VenZRARGsQrXnCU39hu45m1JcwZncSCcalWx1Fu5Oo/3Q8C64wxucC63i2cfdYAAAh9SURBVOenagduNcZMABYBz4hIvIv7VcqvxEWFcuXkYazYUUFrl7Unb59cU0xTRzc/vSJPp1DwM64W/mLgpd7HLwFfPnUDY0yJMeZA7+NKoBpIcXG/Svmdm2Zl0mZzsNzCSzR3lTfy6uYybpuTRd6wIZblUIPD1cJPM8acnNS7CvjCCbJFZCYQBhw6zft3iEihiBTW1NS4GE0p3zJtRDwThg3hhU8O47DgzluH0/Czv+0hOSacH16sN1n5ozMWvoisFZE9/Xwt7rud6Zny77R/S0UkHXgZ+IYxxtnfNsaYpcaYfGNMfkqK/hCgAouI8IOLciitabNk2uS/bDnGzvImHr58vF6G6adCzrSBMabgdO+JyAkRSTfGHO8t9OrTbDcEeBd42BizccBplfJziyYMZUxaDP/594NcOXmYx5YQrGnp4ok1+5mVncjiqcM8sk/lea4O6awAbut9fBuw/NQNRCQMeBv4kzHmTRf3p5RfCwoS7lqQy8HqVt7b45klEI0xPPz2btptDh778kQ9UevHXC38x4GLReQAUND7HBHJF5Hne7e5DpgP3C4iO3q/prq4X6X81uWT0slJjeE/1h3wyCyaf9tRwfv7TnDfxWPITYsd9P0p67hU+MaYOmPMQmNMrjGmwBhT3/t6oTHm272P/2yMCTXGTO3ztcMd4ZXyR8FBwl0Lcig50crqvVWDuq+qpk6WLN/L9JEJfHveqEHdl7Ke3kKnlBe6cvIwRqVE8+SaYjq7HYOyD2MMD7y1i26Hk6euneKx8wXKOlr4Snmh4CDh0asncri2jf9Yd2BQ9vHs+lI+KqnhocvGk50cPSj7UN5FC18pLzU3N5lrpmfw7PpS9la6d46d9SU1PLF6P1dMSufW2SPd+tnKe2nhK+XFfnrFeBKiwnjgrV3YHf3evnLOjta1cddr2xmTFsuT107Wq3ICiBa+Ul4sPiqMRxdPYE9FM0s/LnX581o6u7njT1sBWHpLPlFhZ7wVR/kRLXylvNxlE4dy2cShPLWmmPd2D/za/Kb2br7+wmYO1bTyu5umkZkU5caUyhdo4Svl5USEp6+bwtQR8dzz+g4+PnDu80zVtXZx43MbKaps5g9fn868XJ26JBBp4SvlA6LCQvif22cyKiWa7768lW1lDWf93x6pbeOGpRsprW3l+dvyuTjvC+c4VH5MC18pHxEXFcqfvjWT1Nhwbli6kd+uPfCF1+jb7E5+/+FBLn1mPVXNnbz4jZnMH6NH9oFMz9go5UNSYyN447uz+cXKffxmbQnLtpdz3yVjmZoRT0ZCJCJQcqKVDYdqeXVzGSUnWrl80lAeuWoCaUMirI6vLCY9sxp7n/z8fFNYWGh1DKW81icHalmyfA+ltW0AhIcEERkWTGN7NwDZydE8fPl4CnQIJ6CIyFZjTH5/7+kRvlI+am5uMqvvnc/uikYOVrdy4EQrzZ3d5I9MZPboJEYk6lU46vO08JXyYWEhQUwfmcj0kYlWR1E+QE/aKqVUgNDCV0qpAKGFr5RSAUILXymlAoQWvlJKBQgtfKWUChBa+EopFSC08JVSKkB47dQKIlIDHHXhI5KBWjfFcSfNdW4017nRXOfGH3ONNMb0O0ue1xa+q0Sk8HTzSVhJc50bzXVuNNe5CbRcOqSjlFIBQgtfKaUChD8X/lKrA5yG5jo3muvcaK5zE1C5/HYMXyml1Of58xG+UkqpPrTwlVIqQPh94YvIfSJiRCTZ6iwnici/icguEdkhIu+LyDAvyPSkiOzvzfW2iMRbnekkEblWRPaKiFNELL2ETkQWiUixiBwUkQetzNKXiPy3iFSLyB6rs/QlIiNE5EMR2df7Z3iP1ZkARCRCRDaLyM7eXL+wOtNJIhIsIttFZKW7P9uvC19ERgCXAGVWZznFk8aYycaYqcBKYInVgYAPgInGmMlACfCQxXn62gN8FVhvZQgRCQZ+D1wG5AE3ikielZn6eBFYZHWIftiB+4wxecD5wA+85PesC1hgjJkCTAUWicj5Fmc66R6gaDA+2K8LH/gN8GPAq85MG2Oa+zyNxgvyGWPeN8bYe59uBDKszNOXMabIGFNsdQ5gJnDQGFNqjLEBrwOLLc4EgDFmPVBvdY5TGWOOG2O29T5uoafIhlubCkyP1t6nob1fln8fikgGcAXw/GB8vt8WvogsBiqMMTutztIfEfmliBwDbsY7jvD7+ibwntUhvNBw4Fif5+V4QXn5ChHJAqYBm6xN0qN36GQHUA18YIzxhlzP0HOQ6hyMD/fpRcxFZC0wtJ+3HgZ+Qs9wjiW+KJsxZrkx5mHgYRF5CLgTeMTqTL3bPEzPj+GvDHaec82mfJeIxABvAfee8hOuZYwxDmBq7/mqt0VkojHGsnMgInIlUG2M2SoiXxqMffh04RtjCvp7XUQmAdnAThGBnuGJbSIy0xhTZWW2frwCrMIDhX+mTCJyO3AlsNB4+AaNc/j9slIFMKLP84ze19QXEJFQesr+FWPMMqvznMoY0ygiH9JzDsTKk94XAFeLyOVABDBERP5sjPm6u3bgl0M6xpjdxphUY0yWMSaLnh+9z/NU2Z+JiOT2eboY2G9VlpNEZBE9P0pebYxptzqPl9oC5IpItoiEATcAKyzO5NWk54jrBaDIGPNrq/OcJCIpJ69EE5FI4GIs/j40xjxkjMno7awbgL+7s+zBTwvfBzwuIntEZBc9w07ecKna74BY4IPey0X/aHWgk0TkKyJSDswG3hWRNVbk6D2pfSewhp6Tj28YY/ZakeVUIvIasAEYKyLlIvItqzP1ugC4BVjQ+/dqR+8RrNXSgQ97vwe30DOG7/bLIL2NTq2glFIBQo/wlVIqQGjhK6VUgNDCV0qpAKGFr5RSAUILXymlAoQWvlJKBQgtfKWUChD/HwIAQ4o/N1dQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorized_grad_fn = jax.vmap(jax.grad(jax.scipy.stats.norm.pdf))\n",
    "\n",
    "plt.plot(x, vectorized_grad_fn(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "811BIq8AgpiP"
   },
   "source": [
    "Nice! This is very useful in practice if you want to get per-sample gradients which has some known applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Upa2dPzRzlvt"
   },
   "source": [
    "## JIT Compilation\n",
    "Lets now switch to the area of performance by creating a function we will call `n_dots` that will iteratively call the `dot` function `1000` times over our input `x` by applying `w`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpgo3Alam-xO"
   },
   "outputs": [],
   "source": [
    "def n_dots(x, w):\n",
    "  for i in range(200):\n",
    "    a = jnp.dot(x, w) + x\n",
    "    x = jnp.dot(x, a.mean(axis=[0, 1]))\n",
    "  return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C7ZTvjphfUd"
   },
   "source": [
    "We will first create some random matrices using `jax.random`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bw_WivKalRO1"
   },
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(42)\n",
    "key1, key2 = jax.random.split(key, 2)\n",
    "\n",
    "x = jax.random.uniform(key1, shape=(8, 10, 256, 256))\n",
    "w = jax.random.uniform(key2, shape=(256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axuSkmWjivWX"
   },
   "source": [
    "Notice how we derived 2 random keys `key1` and `key2` by splitting a base key, and we feed these keys to the `uniform` function. Using these arrays we can now benchmark `n_dots` with `timeit`: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdOoh_B-isSf",
    "outputId": "c49d35c7-1a71-4200-9693-990e56899180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 5: 1.6 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit n_dots(x, w).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ghj8jJxiC1g"
   },
   "source": [
    "Notice that we use `.block_until_ready()`, this is needed because Jax has an asynchronous model that queues computation the devices in the background and returns almost inmediately which would be misleading.\n",
    "\n",
    "Now the previous computation is quite slow in part because of the Python interpreter but also because Jax's eager mode is not optimized. We can do a lot better if we compile the whole computation into a single XLA program via the `jit` transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "FKl5PLrCl8Ta",
    "outputId": "74a555e2-282e-4106-a9f6-f69e31c3f02c"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnfilteredStackTrace\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-867a9c0d84c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mn_dots_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# benchmark trick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done jitting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         donated_invars=donated_invars, inline=inline)\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0mout_pytree_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1631\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1622\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    626\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    687\u001b[0m   compiled_fun = _xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0;32m--> 688\u001b[0;31m                                *unsafe_map(arg_spec, args))\n\u001b[0m\u001b[1;32m    689\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mmemoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, device, backend, name, donated_invars, *arg_specs)\u001b[0m\n\u001b[1;32m    759\u001b[0m   return lower_xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0;32m--> 760\u001b[0;31m                             *arg_specs).compile().unsafe_call\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mlower_xla_callable\u001b[0;34m(fun, device, backend, name, donated_invars, *arg_specs)\u001b[0m\n\u001b[1;32m    771\u001b[0m   jaxpr, out_avals, consts = pe.trace_to_jaxpr_final(\n\u001b[0;32m--> 772\u001b[0;31m       fun, abstract_args, pe.debug_info_final(fun, \"jit\"))\n\u001b[0m\u001b[1;32m    773\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_final\u001b[0;34m(fun, in_avals, debug_info)\u001b[0m\n\u001b[1;32m   1541\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m       \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_subjaxpr_dynamic\u001b[0;34m(fun, main, in_avals)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     \u001b[0min_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m     \u001b[0mout_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-8363b7b2e0f4>\u001b[0m in \u001b[0;36mn_dots\u001b[0;34m(x, w)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         donated_invars=donated_invars, inline=inline)\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0mout_pytree_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1631\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1622\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, call_primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m       \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_subjaxpr_dynamic\u001b[0;34m(fun, main, in_avals)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     \u001b[0min_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m     \u001b[0mout_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   4791\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4792\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(lhs, rhs, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m    692\u001b[0m     raise TypeError(\"Incompatible shapes for dot: got {} and {}.\".format(\n\u001b[0;32m--> 693\u001b[0;31m         lhs.shape, rhs.shape))\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnfilteredStackTrace\u001b[0m: TypeError: Incompatible shapes for dot: got (100,) and (256, 256).\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-867a9c0d84c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_dots_jit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_dots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mn_dots_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# benchmark trick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done jitting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-8363b7b2e0f4>\u001b[0m in \u001b[0;36mn_dots\u001b[0;34m(x, w)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mn_dots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   4790\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4791\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4792\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4794\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mb_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Incompatible shapes for dot: got (100,) and (256, 256)."
     ]
    }
   ],
   "source": [
    "n_dots_jit = jax.jit(n_dots)\n",
    "\n",
    "n_dots_jit(x, w) # benchmark trick\n",
    "print(\"done jitting\")\n",
    "\n",
    "%timeit n_dots_jit(x, w).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMRFiCdomjJD"
   },
   "source": [
    "This is more than a **10x** improvement 🚀. This is amazing but can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDgANjdZldFp"
   },
   "source": [
    "## Parallelization\n",
    "\n",
    "`vmap` allows parallelization on a single device\n",
    "\n",
    "`pmap` allows parallelization across multiple devices. Ex: TPU Cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69qCNnRsXyPR",
    "outputId": "60b28bbe-c6ed-4e80-c343-65fc96b40040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done jitting\n",
      "100 loops, best of 5: 12.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "n_dots_pmap = jax.pmap(n_dots, in_axes=(0, None))\n",
    "\n",
    "n_dots_pmap(x, w)\n",
    "print(\"done jitting\")\n",
    "\n",
    "%timeit n_dots_pmap(x, w).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J507iLPnrIg"
   },
   "source": [
    "This is an extra **5x** over `jit` 🚀🚀🚀. Notice that we use `in_axes=(0, None)` This means that we are slicing over the first dimension of the first input `x` but not slicing (replicating) the second input `w`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vceeLP_qtA7I"
   },
   "source": [
    "## Pytrees\n",
    "Jax offers the concept of a Pytree which is extreemly useful to manimulate complex states, this become important as you do more complex stuff since Jax is very explicit about state handling because of its functional design. \n",
    "\n",
    "We can loosely define a `Pytree` as **any structure which can be flattened**.  Lets create a simple example of such a structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXHf6GwBsBgY",
    "outputId": "44a9af76-58a3-451a-d9cd-03e2f55efc17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [1.0, 2.0], 'b': (3.0, {'c': 4.0, 'd': 5.0})}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = {\"a\": [1.0, 2.0], \"b\": (3.0, {\"c\": 4.0, \"d\": 5.0})}\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tj9NKIoprZ6U"
   },
   "source": [
    "Here we used dictionaries, lists and tuples to create a nested structure, we can also define register our custom types as pytrees but we will not cover this here. Now, flattening this pytree would be a tipical interview question but Jax lets us do this easily by using the `tree_leaves` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVXAEwrf555z",
    "outputId": "f685e962-8291-4fcb-971e-e341ff574a66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0, 4.0, 5.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_leaves(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Bt6RfL8sJbH"
   },
   "source": [
    "We can also map over a pytree by using the `tree_map` function which behaves a bit like `map` but keeps the shape of the original structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBjhIL2c6Dk2",
    "outputId": "36a2a8a4-12ea-4f7d-d1e7-8e78dd59ae4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [10.0, 20.0], 'b': (30.0, {'c': 40.0, 'd': 50.0})}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x: 10 * x, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoCNT7rSsoMM"
   },
   "source": [
    "Here we multiplied each leaf element by `10`. We can also leaf-wise operations between 2 pytrees if they have the same structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUx--ov16JUa",
    "outputId": "99c46c32-976e-4f20-8569-a7b1f793ee6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [1.0, 4.0], 'b': (9.0, {'c': 16.0, 'd': 25.0})}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x, y: x * y, tree, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VW91qsOitNUi"
   },
   "source": [
    "Here we multiplied the elements between 2 pytrees, for simplicity we just reused `tree` but this works in general. \n",
    "\n",
    "Ok, this is very cool but why do we really care about this? The reason most of the basic transformations in Jax and many of the libraries support pytrees. To see this lets do something a bit strange, lets create a loss function our our tree structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYwvPQTc9IrW",
    "outputId": "be293360-494e-4a33-d08c-8fb74a59b3c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tree_loss(tree):\n",
    "  return sum((x ** 2 for x in jax.tree_leaves(tree)), 0.0)\n",
    "\n",
    "tree_loss(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOu1d5GPuKXK"
   },
   "source": [
    "To define this loss function we leverages `tree_leaves` to square each element before adding them up using `sum`. The next obvious step is seen if we can define can calculate the gradient for our loss function for this tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_KRfALR6VmC",
    "outputId": "f50341e1-4e1a-421f-946c-4b92527def75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [2.0, 4.0], 'b': (6.0, {'c': 8.0, 'd': 10.0})}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grad = jax.grad(tree_loss)\n",
    "\n",
    "# tree_grad(tree)\n",
    "jax.tree_map(float, tree_grad(tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8MA4uZIxPyw"
   },
   "source": [
    "An it works just fine! Notice that the gradient of the loss has the same shape as our tree 😄. Putting everything together we can perform gradient descent to get the minimum tree by using `jit` and `tree_multimap`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_eU-wFgcuoZo",
    "outputId": "cc5fdc13-e90e-483d-e274-e4303c44551d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [4.074073578497206e-10, 8.148147156994412e-10],\n",
       " 'b': (1.2222216572155276e-09,\n",
       "  {'c': 1.6296294313988824e-09, 'd': 2.0370367614930274e-09})}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_min = tree\n",
    "\n",
    "def gradient_descent(p, g):\n",
    "  return p - 0.1 * g\n",
    "\n",
    "@jax.jit\n",
    "def update(tree):\n",
    "    grads = tree_grad(tree)\n",
    "    tree = jax.tree_map(gradient_descent, tree, grads) #GD\n",
    "    return tree\n",
    "\n",
    "for i in range(100):\n",
    "    tree_min = update(tree_min)\n",
    "\n",
    "jax.tree_map(float, tree_grad(tree_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWsQ9eMsx3ZH"
   },
   "source": [
    "Beautiful! The optimal solution is all zeros so we are very close."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Jax 201.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
